#!/usr/bin/env python3
"""
ğŸ¯ Dynamic Prompt Management System

âœ¨ This module creates context-aware, dynamic prompts instead of hardcoded ones.
ğŸ§  AI assistants can generate contextual prompts based on:
   - Current event details
   - User preferences
   - Real-time conditions
   - Historical performance data

ğŸ¨ Features:
   - ğŸ“ Template-based prompt generation
   - ğŸ”„ Context injection
   - ğŸ“Š Performance tracking
   - ğŸ›ï¸ User customization
"""

import json
import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path
from dataclasses import dataclass, field


@dataclass
class PromptContext:
    """ğŸ¯ Context data for dynamic prompt generation"""
    event_name: str
    event_type: str  # ğŸ›ï¸ political, ğŸŒ environmental, ğŸ­ cultural, etc.
    locations: List[str] = field(default_factory=list)
    urgency_level: str = "medium"  # ğŸ”¥ high, âš–ï¸ medium, ğŸŒ± low
    time_sensitivity: bool = True
    user_preferences: Dict[str, Any] = field(default_factory=dict)
    previous_results: Dict[str, Any] = field(default_factory=dict)


class DynamicPromptGenerator:
    """
    ğŸ¨ Dynamic Prompt Generator
    
    Creates contextual, adaptive prompts instead of static templates.
    Each prompt is tailored to the specific situation and requirements.
    """
    
    def __init__(self, templates_dir: str = "prompts"):
        self.templates_dir = Path(templates_dir)
        self.performance_log = self.templates_dir / "prompt_performance.json"
        self.user_preferences = self.templates_dir / "user_preferences.json"
        
        # ğŸ“Š Load performance data and preferences
        self.performance_data = self._load_performance_data()
        self.preferences = self._load_user_preferences()
    
    def generate_trending_events_prompt(self, context: PromptContext) -> str:
        """
        ğŸŒŸ Generate dynamic prompt for trending events discovery
        
        Args:
            context: Current context and requirements
            
        Returns:
            Contextual prompt optimized for the current situation
        """
        urgency_emoji = {
            "high": "ğŸ”¥",
            "medium": "âš–ï¸", 
            "low": "ğŸŒ±"
        }[context.urgency_level]
        
        # ğŸ¯ Customize based on event type preference
        event_focus = self._get_event_focus(context.event_type)
        
        # ğŸŒ Location-specific instructions
        location_instruction = self._get_location_instruction(context.locations)
        
        prompt = f"""
{urgency_emoji} **TRENDING EVENTS DISCOVERY - {context.urgency_level.upper()} PRIORITY**

You're an expert AI news scout with real-time awareness. Your mission:

ğŸ¯ **PRIMARY OBJECTIVE**: Identify 7 trending events happening RIGHT NOW
{event_focus}
{location_instruction}

ğŸ“‹ **OUTPUT FORMAT** (for each event):
- ğŸ·ï¸ **Event Title**: [Clear, specific title]
- ğŸ“ **Description**: [One impactful sentence]
- ğŸ“ **Location**: [Primary location/region]
- ğŸ¨ **Visual**: [Relevant emoji for instant recognition]
- â° **Time Context**: [How recent/urgent]

ğŸ¯ **QUALITY CRITERIA**:
âœ… Events must be happening within the last 24 hours
âœ… Prioritize events with real-time developments
âœ… Focus on events with visual/social media coverage
âœ… Include diverse geographic representation

ğŸš€ **EXECUTION**: Present as numbered list, most urgent first!
"""
        
        # ğŸ“Š Log prompt generation for performance tracking
        self._log_prompt_usage("trending_events", {
            "event_name": context.event_name,
            "event_type": context.event_type,
            "urgency_level": context.urgency_level
        })
        
        return prompt.strip()
    
    def generate_event_analysis_prompt(self, context: PromptContext) -> str:
        """
        ğŸ§  Generate dynamic event analysis prompt
        
        Creates contextual analysis instructions based on event characteristics
        """
        event_emoji = self._get_event_emoji(context.event_type)
        
        # ğŸ›ï¸ Customize analysis depth based on urgency
        analysis_depth = self._get_analysis_depth(context.urgency_level)
        
        # ğŸ” Source prioritization based on event type
        source_priorities = self._get_source_priorities(context.event_type)
        
        prompt = f"""
{event_emoji} **EVENT ANALYSIS & SEARCH STRATEGY**

ğŸ¯ **TARGET EVENT**: {context.event_name}
ğŸ“Š **Analysis Level**: {analysis_depth}

### ğŸ“Œ CONTEXTUAL SUMMARY
Provide a focused 2-3 sentence analysis covering:
- ğŸ¯ **Core Issue**: What's the fundamental situation?
- ğŸŒ **Geographic Impact**: Where and why it matters
- â° **Current Status**: What's happening right now

### ğŸ“ IMPACT ZONES
Identify key locations experiencing direct effects from this event.

### ğŸ” INTELLIGENT SEARCH STRATEGY
{source_priorities}

For each category, provide:
- **ğŸ¯ Optimized Query**: Exact search terms for maximum relevance
- **ğŸ’¡ Strategic Value**: Why this source matters for this specific event
- **âš¡ Real-time Focus**: How to capture live developments

### ğŸš€ EXECUTION PRIORITY
Start with the most time-sensitive category for immediate intelligence gathering.
"""
        
        self._log_prompt_usage("event_analysis", {
            "event_name": context.event_name,
            "event_type": context.event_type,
            "urgency_level": context.urgency_level
        })
        return prompt.strip()
    
    def generate_content_retrieval_prompt(self, platform: str, query: str, context: PromptContext) -> str:
        """
        ğŸ“¥ Generate dynamic content retrieval prompt
        
        Args:
            platform: Target platform (twitter, youtube, official, webcam)
            query: Search query
            context: Event context
        """
        platform_config = {
            "twitter": {
                "emoji": "ğŸ¦",
                "focus": "real-time updates, eyewitness accounts, official statements",
                "metrics": "engagement rates, verification status, recency"
            },
            "youtube": {
                "emoji": "ğŸ“º", 
                "focus": "live streams, recent uploads, authoritative channels",
                "metrics": "view counts, upload recency, channel credibility"
            },
            "official": {
                "emoji": "ğŸ›ï¸",
                "focus": "government statements, agency reports, verified sources",
                "metrics": "source authority, document recency, official verification"
            },
            "webcam": {
                "emoji": "ğŸ“¹",
                "focus": "live feeds, real-time visuals, geographic coverage",
                "metrics": "stream quality, viewer count, location accuracy"
            }
        }
        
        config = platform_config.get(platform, platform_config["twitter"])
        
        # ğŸ¯ Urgency-based result count
        result_count = {
            "high": "5-7",
            "medium": "3-5", 
            "low": "2-3"
        }[context.urgency_level]
        
        prompt = f"""
{config['emoji']} **{platform.upper()} INTELLIGENCE GATHERING**

ğŸ¯ **SEARCH QUERY**: "{query}"
ğŸ“Š **TARGET RESULTS**: {result_count} highest-quality items
â° **URGENCY LEVEL**: {context.urgency_level}

### ğŸ” SEARCH FOCUS
{config['focus']}

### ğŸ“Š QUALITY METRICS
Prioritize based on: {config['metrics']}

### ğŸ“‹ REQUIRED DATA POINTS
For each item, extract:
- ğŸ‘¤ **Source**: Username/channel name + verification status
- ğŸ“ **Content**: Full text/title + key summary
- â° **Timestamp**: Exact posting/upload time
- ğŸ“Š **Engagement**: Likes, shares, views (as available)
- ğŸ”— **Direct Link**: Full URL for verification
- ğŸ¯ **Relevance Score**: How well it matches our event (1-10)

### ğŸš€ EXECUTION PROTOCOL
1. ğŸ” Execute search with provided query
2. ğŸ“Š Rank results by relevance and quality metrics
3. ğŸ“‹ Present top results in structured format
4. â³ Await approval before deeper analysis

ğŸ¯ **SUCCESS CRITERIA**: Results must provide actionable intelligence about "{context.event_name}"
"""
        
        self._log_prompt_usage(f"{platform}_retrieval", {
            "query": query,
            "event_name": context.event_name,
            "event_type": context.event_type,
            "urgency_level": context.urgency_level
        })
        return prompt.strip()
    
    def _get_event_focus(self, event_type: str) -> str:
        """ğŸ¯ Get event-type specific focus instructions"""
        focus_map = {
            "political": "ğŸ›ï¸ **Focus**: Political developments, policy changes, electoral events",
            "environmental": "ğŸŒ **Focus**: Environmental incidents, climate events, natural disasters",
            "social": "ğŸ‘¥ **Focus**: Social movements, community events, cultural developments",
            "economic": "ğŸ’° **Focus**: Market movements, economic policy, business developments",
            "technology": "ğŸ’» **Focus**: Tech launches, cyber events, innovation announcements",
            "security": "ğŸ›¡ï¸ **Focus**: Security incidents, safety events, emergency responses"
        }
        return focus_map.get(event_type, "ğŸ¯ **Focus**: All significant real-time developments")
    
    def _get_location_instruction(self, locations: List[str]) -> str:
        """ğŸŒ Generate location-specific instructions"""
        if not locations:
            return "ğŸŒ **Geographic Scope**: Global events with significant impact"
        
        location_str = ", ".join(locations)
        return f"ğŸ“ **Priority Regions**: Focus on events in or affecting {location_str}"
    
    def _get_event_emoji(self, event_type: str) -> str:
        """ğŸ¨ Get appropriate emoji for event type"""
        emoji_map = {
            "political": "ğŸ›ï¸",
            "environmental": "ğŸŒ", 
            "social": "ğŸ‘¥",
            "economic": "ğŸ’°",
            "technology": "ğŸ’»",
            "security": "ğŸ›¡ï¸"
        }
        return emoji_map.get(event_type, "ğŸ¯")
    
    def _get_analysis_depth(self, urgency: str) -> str:
        """ğŸ“Š Determine analysis depth based on urgency"""
        depth_map = {
            "high": "ğŸ”¥ **RAPID RESPONSE** - Immediate actionable intelligence",
            "medium": "âš–ï¸ **COMPREHENSIVE** - Balanced analysis with multiple perspectives",
            "low": "ğŸŒ± **THOROUGH** - Deep dive with historical context"
        }
        return depth_map[urgency]
    
    def _get_source_priorities(self, event_type: str) -> str:
        """ğŸ” Get source priorities based on event type"""
        priority_map = {
            "political": """
**ğŸ›ï¸ Official Government Sources** (Highest Priority)
**ğŸ¦ Political Twitter/Social** (Real-time reactions)
**ğŸ“º News Live Streams** (Breaking coverage)
**ğŸ“¹ Live Event Feeds** (Direct visuals)
""",
            "environmental": """
**ğŸŒ Environmental Agencies** (Official data)
**ğŸ“¹ Live Webcams/Satellite** (Real-time visuals)
**ğŸ¦ Eyewitness Social Media** (Ground reports)
**ğŸ“º Scientific/News Sources** (Expert analysis)
"""
        }
        
        return priority_map.get(event_type, """
**ğŸ¦ Social Media Updates** (Real-time pulse)
**ğŸ“º Video Coverage** (Visual documentation)
**ğŸ›ï¸ Official Statements** (Authoritative sources)
**ğŸ“¹ Live Visual Feeds** (Direct observation)
""")
    
    def _load_performance_data(self) -> Dict:
        """ğŸ“Š Load prompt performance metrics"""
        try:
            if self.performance_log.exists():
                return json.loads(self.performance_log.read_text())
        except Exception:
            pass
        return {}
    
    def _load_user_preferences(self) -> Dict:
        """ğŸ›ï¸ Load user customization preferences"""
        try:
            if self.user_preferences.exists():
                return json.loads(self.user_preferences.read_text())
        except Exception:
            pass
        return {
            "preferred_sources": ["twitter", "youtube", "official"],
            "urgency_bias": "medium",
            "location_focus": [],
            "event_type_priority": ["political", "environmental", "social"]
        }
    
    def _log_prompt_usage(self, prompt_type: str, context: Dict) -> None:
        """ğŸ“Š Log prompt usage for performance analysis"""
        timestamp = datetime.datetime.now().isoformat()
        
        if prompt_type not in self.performance_data:
            self.performance_data[prompt_type] = []
        
        self.performance_data[prompt_type].append({
            "timestamp": timestamp,
            "context": context,
            "success": None  # To be updated later with results
        })
        
        # ğŸ’¾ Save performance data
        try:
            self.performance_log.parent.mkdir(exist_ok=True)
            self.performance_log.write_text(json.dumps(self.performance_data, indent=2))
        except Exception as e:
            print(f"âš ï¸ Warning: Could not save performance data: {e}")


# ğŸ¯ Example usage and testing
if __name__ == "__main__":
    # ğŸ§ª Test the dynamic prompt system
    generator = DynamicPromptGenerator()
    
    # ğŸ¯ Create test context
    test_context = PromptContext(
        event_name="Climate Summit Protests in Glasgow",
        event_type="environmental",
        locations=["Glasgow", "Scotland"],
        urgency_level="high",
        time_sensitivity=True
    )
    
    # ğŸŒŸ Generate trending events prompt
    trending_prompt = generator.generate_trending_events_prompt(test_context)
    print("ğŸŒŸ TRENDING EVENTS PROMPT:")
    print(trending_prompt)
    print("\n" + "="*50 + "\n")
    
    # ğŸ§  Generate analysis prompt
    analysis_prompt = generator.generate_event_analysis_prompt(test_context)
    print("ğŸ§  EVENT ANALYSIS PROMPT:")
    print(analysis_prompt)
    print("\n" + "="*50 + "\n")
    
    # ğŸ¦ Generate Twitter retrieval prompt
    twitter_prompt = generator.generate_content_retrieval_prompt(
        "twitter", 
        "Glasgow climate summit protests live updates",
        test_context
    )
    print("ğŸ¦ TWITTER RETRIEVAL PROMPT:")
    print(twitter_prompt)

